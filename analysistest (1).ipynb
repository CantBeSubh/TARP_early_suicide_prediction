{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from textblob import Word\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/aman/coding stuff/sem 6/tarp/dataset/Suicide_preprocessed3.csv\")\n",
    "#df = pd.read_csv( \"/Users/aman/coding stuff/sem 6/tarp/dataset/Suicide_preprocessed1.csv\", index_col=None, header=0, engine='python' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Am I weird I don t get affected by compliments...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Finally is almost over So I can never hear has...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>i need helpjust help me im crying so hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I m so lostHello my name is Adam and I ve been...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Honetly idkI dont know what im even doing here...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigger warning Excuse for self inflicted bur...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>It ends tonight I can t do it anymore I quit</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Everyone wants to be edgy and it s making me s...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>My life is over at years oldHello all I am a y...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           0  Ex Wife Threatening SuicideRecently I left my ...      suicide\n",
       "1           1  Am I weird I don t get affected by compliments...  non-suicide\n",
       "2           2  Finally is almost over So I can never hear has...  non-suicide\n",
       "3           3          i need helpjust help me im crying so hard      suicide\n",
       "4           4  I m so lostHello my name is Adam and I ve been...      suicide\n",
       "5           5  Honetly idkI dont know what im even doing here...      suicide\n",
       "6           6   Trigger warning Excuse for self inflicted bur...      suicide\n",
       "7           7      It ends tonight I can t do it anymore I quit       suicide\n",
       "8           8  Everyone wants to be edgy and it s making me s...  non-suicide\n",
       "9           9  My life is over at years oldHello all I am a y...      suicide"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m l\u001b[39m=\u001b[39m[]\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10000\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     l\u001b[39m.\u001b[39mappend(TextBlob(df\u001b[39m.\u001b[39;49miloc[i,\u001b[39m1\u001b[39;49m])\u001b[39m.\u001b[39msentiment\u001b[39m.\u001b[39mpolarity)\n\u001b[1;32m      4\u001b[0m l1\u001b[39m=\u001b[39m[]\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m l:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1064\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(com\u001b[39m.\u001b[39mapply_if_callable(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_value(\u001b[39m*\u001b[39;49mkey, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n\u001b[1;32m   1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/frame.py:3915\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3913\u001b[0m \u001b[39mif\u001b[39;00m takeable:\n\u001b[1;32m   3914\u001b[0m     series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ixs(col, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 3915\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39;49m_values[index]\n\u001b[1;32m   3917\u001b[0m series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_item_cache(col)\n\u001b[1;32m   3918\u001b[0m engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_engine\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for i in range(10000):\n",
    "    l.append(TextBlob(df.iloc[i,1]).sentiment.polarity)\n",
    "l1=[]\n",
    "for i in l:\n",
    "    if i>=0.2:\n",
    "        l1.append(\"non-suicide\")\n",
    "    else:\n",
    "        l1.append(\"suicide\")\n",
    "l2=df.iloc[0:10000,2].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(accuracy_score(l1,l2))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(l1,l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/aman/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/aman/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "    # Lemmatization\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join([Word(x).lemmatize() for x in x.split()]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 713, 120)          60000     \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 713, 120)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 704)               2323200   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 352)               248160    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 1059      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,632,419\n",
      "Trainable params: 2,632,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "[[  0   0   0 ...  22 120  43]\n",
      " [  0   0   0 ...   2  14 404]\n",
      " [290 105 106 ... 303  11 357]\n",
      " ...\n",
      " [  0   0   0 ...  36  24 143]\n",
      " [  0   0   0 ... 315  79 118]\n",
      " [  0   0   0 ...  69 165 164]] [[  0   0   0 ... 253  89   2]\n",
      " [  0   0   0 ...  43 445   1]\n",
      " [  0   0   0 ...  98  15  81]\n",
      " ...\n",
      " [  0   0   0 ...  26 356   4]\n",
      " [  0   0   0 ...   3  27  45]\n",
      " [  0   0   0 ...  56 118  10]] [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]] [[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 22:39:01.595342: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 17s 4s/step - loss: 1.0640 - accuracy: 0.5125\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 14s 4s/step - loss: 1.2800 - accuracy: 0.4750\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.8815 - accuracy: 0.5750\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.8657 - accuracy: 0.5750\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.7469 - accuracy: 0.5750\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.7084 - accuracy: 0.5750\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.6473 - accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.6640 - accuracy: 0.6250\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.5818 - accuracy: 0.8375\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.4718 - accuracy: 0.8125\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.4264 - accuracy: 0.7875\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.5310 - accuracy: 0.6375\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.4121 - accuracy: 0.7875\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.3196 - accuracy: 0.9375\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 15s 4s/step - loss: 0.2527 - accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 16s 5s/step - loss: 0.1753 - accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 17s 5s/step - loss: 0.1291 - accuracy: 0.9375\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 17s 5s/step - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.0451 - accuracy: 0.9750\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.0349 - accuracy: 0.9750\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7165 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.716536819934845, 0.800000011920929]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Generating Embeddings using tokenizer\n",
    "df=df.iloc[0:100,:]\n",
    "data_cleaned=cleaning(df)\n",
    "tokenizer = Tokenizer(num_words=500, split=' ') \n",
    "tokenizer.fit_on_texts(data_cleaned['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data_cleaned['text'].values)\n",
    "X = pad_sequences(X)\n",
    "#Model Building\n",
    "model = Sequential()\n",
    "model.add(Embedding(500, 120, input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(704, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(352, activation='LeakyReLU'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "df[\"class\"]=preprocessing.LabelEncoder().fit_transform(df[\"class\"])\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,df[\"class\"],test_size=0.2)\n",
    "\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)\n",
    "#Model Training\n",
    "print(X_train,X_test,y_train,y_test)\n",
    "model.fit(X_train, y_train, epochs = 20, batch_size=32, verbose =1)\n",
    "#Model Testing\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.7165 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.716536819934845, 0.800000011920929]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...  22 120  43]\n",
      " [  0   0   0 ...   2  14 404]\n",
      " [290 105 106 ... 303  11 357]\n",
      " ...\n",
      " [  0   0   0 ...  36  24 143]\n",
      " [  0   0   0 ... 315  79 118]\n",
      " [  0   0   0 ...  69 165 164]] 80\n",
      "[[  0   0   0 ... 253  89   2]\n",
      " [  0   0   0 ...  43 445   1]\n",
      " [  0   0   0 ...  98  15  81]\n",
      " ...\n",
      " [  0   0   0 ...  26 356   4]\n",
      " [  0   0   0 ...   3  27  45]\n",
      " [  0   0   0 ...  56 118  10]] 20\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]] 80\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]] 20\n"
     ]
    }
   ],
   "source": [
    "print(X_train,len(X_train))\n",
    "print(X_test,len(X_test))\n",
    "print(y_train,len(y_train))\n",
    "print(y_test,len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text=df[\"text\"].tolist()\n",
    "df_class=df[\"class\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11976\n",
      "232074\n",
      "220098\n"
     ]
    }
   ],
   "source": [
    "wantedRows = df[df[\"text\"].str.split().str.len()>250].index \n",
    "print(len(wantedRows))\n",
    "print(len(df))\n",
    "df_less_450 =  df[\"text\"].drop(wantedRows, axis = 0)\n",
    "print(len(df_less_450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Ex Wife Threatening SuicideRecently left wife ...\n",
       "1         weird not get affected compliments coming some...\n",
       "2         Finally almost never hear bad year ever swear ...\n",
       "3                         need helpjust help me crying hard\n",
       "4         lostHello name Adam and struggling years and a...\n",
       "                                ...                        \n",
       "232069    you not like rock not going get anything but g...\n",
       "232070    You you tell many friends and not lonely and e...\n",
       "232071    pee probably tastes like salty tea someone dra...\n",
       "232072    usual stuff you find hereI not posting sympath...\n",
       "232073    still not beaten first boss Hollow Knight foug...\n",
       "Name: text, Length: 220098, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_less_450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_less_450\u001b[39m=\u001b[39mdf_less_450\u001b[39m.\u001b[39;49mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "df_less_450=df_less_450.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'NEGATIVE', 'score': 0.9813257455825806}], [{'label': 'POSITIVE', 'score': 0.9924561977386475}], [{'label': 'POSITIVE', 'score': 0.9879748821258545}], [{'label': 'NEGATIVE', 'score': 0.9963231086730957}], [{'label': 'NEGATIVE', 'score': 0.9901783466339111}], [{'label': 'NEGATIVE', 'score': 0.9974479675292969}], [{'label': 'NEGATIVE', 'score': 0.9769376516342163}], [{'label': 'NEGATIVE', 'score': 0.7028540372848511}], [{'label': 'NEGATIVE', 'score': 0.9953219294548035}], [{'label': 'NEGATIVE', 'score': 0.9972437620162964}], [{'label': 'NEGATIVE', 'score': 0.9661169648170471}], [{'label': 'NEGATIVE', 'score': 0.9979548454284668}], [{'label': 'NEGATIVE', 'score': 0.8084930777549744}], [{'label': 'NEGATIVE', 'score': 0.992155909538269}], [{'label': 'NEGATIVE', 'score': 0.9987903237342834}], [{'label': 'NEGATIVE', 'score': 0.9949349761009216}], [{'label': 'NEGATIVE', 'score': 0.9968137145042419}], [{'label': 'NEGATIVE', 'score': 0.9996371269226074}], [{'label': 'NEGATIVE', 'score': 0.9989016056060791}], [{'label': 'NEGATIVE', 'score': 0.9616683721542358}], [{'label': 'NEGATIVE', 'score': 0.9950272440910339}], [{'label': 'NEGATIVE', 'score': 0.9969246983528137}], [{'label': 'NEGATIVE', 'score': 0.7276686429977417}], [{'label': 'NEGATIVE', 'score': 0.9986664056777954}], [{'label': 'NEGATIVE', 'score': 0.9880082607269287}], [{'label': 'NEGATIVE', 'score': 0.9448767304420471}], [{'label': 'NEGATIVE', 'score': 0.9931882619857788}], [{'label': 'POSITIVE', 'score': 0.9965698719024658}], [{'label': 'NEGATIVE', 'score': 0.9978475570678711}], [{'label': 'NEGATIVE', 'score': 0.9826745390892029}], [{'label': 'NEGATIVE', 'score': 0.9045161008834839}], [{'label': 'NEGATIVE', 'score': 0.9945881366729736}], [{'label': 'POSITIVE', 'score': 0.9990144968032837}], [{'label': 'NEGATIVE', 'score': 0.8272981643676758}], [{'label': 'NEGATIVE', 'score': 0.994834303855896}], [{'label': 'NEGATIVE', 'score': 0.998264729976654}], [{'label': 'NEGATIVE', 'score': 0.9067460894584656}], [{'label': 'NEGATIVE', 'score': 0.9891291856765747}], [{'label': 'NEGATIVE', 'score': 0.9851974844932556}], [{'label': 'NEGATIVE', 'score': 0.9942666888237}], [{'label': 'NEGATIVE', 'score': 0.9935744404792786}], [{'label': 'NEGATIVE', 'score': 0.9230472445487976}], [{'label': 'NEGATIVE', 'score': 0.996452808380127}], [{'label': 'NEGATIVE', 'score': 0.9926310777664185}], [{'label': 'NEGATIVE', 'score': 0.9987916350364685}], [{'label': 'NEGATIVE', 'score': 0.9991356730461121}], [{'label': 'NEGATIVE', 'score': 0.9993506073951721}], [{'label': 'POSITIVE', 'score': 0.9920883774757385}], [{'label': 'POSITIVE', 'score': 0.5489084720611572}], [{'label': 'NEGATIVE', 'score': 0.9962182641029358}], [{'label': 'POSITIVE', 'score': 0.9771530628204346}], [{'label': 'NEGATIVE', 'score': 0.9863246083259583}], [{'label': 'POSITIVE', 'score': 0.7187484502792358}], [{'label': 'NEGATIVE', 'score': 0.9786568284034729}], [{'label': 'POSITIVE', 'score': 0.9998565912246704}], [{'label': 'NEGATIVE', 'score': 0.9959486126899719}], [{'label': 'NEGATIVE', 'score': 0.9908297061920166}], [{'label': 'NEGATIVE', 'score': 0.9908754825592041}], [{'label': 'NEGATIVE', 'score': 0.8991801142692566}], [{'label': 'NEGATIVE', 'score': 0.988128125667572}], [{'label': 'NEGATIVE', 'score': 0.9970622658729553}], [{'label': 'NEGATIVE', 'score': 0.9985501170158386}], [{'label': 'NEGATIVE', 'score': 0.9991014003753662}], [{'label': 'POSITIVE', 'score': 0.9996351003646851}], [{'label': 'NEGATIVE', 'score': 0.9915660619735718}], [{'label': 'NEGATIVE', 'score': 0.9857466220855713}], [{'label': 'NEGATIVE', 'score': 0.8715210556983948}], [{'label': 'NEGATIVE', 'score': 0.9417417645454407}], [{'label': 'NEGATIVE', 'score': 0.9935957789421082}], [{'label': 'POSITIVE', 'score': 0.7360411286354065}], [{'label': 'NEGATIVE', 'score': 0.7758479714393616}], [{'label': 'NEGATIVE', 'score': 0.9984574317932129}], [{'label': 'NEGATIVE', 'score': 0.9994738698005676}], [{'label': 'NEGATIVE', 'score': 0.9993554949760437}], [{'label': 'NEGATIVE', 'score': 0.996167004108429}], [{'label': 'NEGATIVE', 'score': 0.9897685050964355}], [{'label': 'NEGATIVE', 'score': 0.9987397789955139}], [{'label': 'NEGATIVE', 'score': 0.982348620891571}], [{'label': 'NEGATIVE', 'score': 0.9390847086906433}], [{'label': 'NEGATIVE', 'score': 0.9981390237808228}], [{'label': 'NEGATIVE', 'score': 0.9983232617378235}], [{'label': 'NEGATIVE', 'score': 0.9982432126998901}], [{'label': 'NEGATIVE', 'score': 0.9923111200332642}], [{'label': 'NEGATIVE', 'score': 0.9976499676704407}], [{'label': 'NEGATIVE', 'score': 0.8348944783210754}], [{'label': 'NEGATIVE', 'score': 0.9263943433761597}], [{'label': 'NEGATIVE', 'score': 0.9970067143440247}], [{'label': 'NEGATIVE', 'score': 0.9958953857421875}], [{'label': 'NEGATIVE', 'score': 0.997557520866394}], [{'label': 'NEGATIVE', 'score': 0.97308748960495}], [{'label': 'NEGATIVE', 'score': 0.9978894591331482}], [{'label': 'NEGATIVE', 'score': 0.9909676909446716}], [{'label': 'NEGATIVE', 'score': 0.9636275172233582}], [{'label': 'NEGATIVE', 'score': 0.9667627215385437}], [{'label': 'POSITIVE', 'score': 0.9990062117576599}], [{'label': 'NEGATIVE', 'score': 0.9902246594429016}], [{'label': 'NEGATIVE', 'score': 0.996609091758728}], [{'label': 'NEGATIVE', 'score': 0.9793359637260437}], [{'label': 'NEGATIVE', 'score': 0.9985902905464172}], [{'label': 'POSITIVE', 'score': 0.578885555267334}]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#tokenized_sentence = tokenizer.encode(df_less_450, padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\",model=model, tokenizer=tokenizer)\n",
    "l1=[]\n",
    "for i in df_less_450[0:100]:\n",
    "    l1.append(sentiment_pipeline(i))\n",
    "print(l1)\n",
    "#print(l1[0][\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "print(l1[0][0][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ex Wife Threatening SuicideRecently left wife ...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>weird not get affected compliments coming some...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Finally almost never hear bad year ever swear ...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>need helpjust help me crying hard</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>lostHello name Adam and struggling years and a...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Honetly idkI not know even feel like nothing a...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Trigger warning Excuse self inflicted burns kn...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>ends tonight cannot anymore quit</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Everyone wants edgy and making me self conscio...</td>\n",
       "      <td>non-suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>life years oldHello year old balding male hair...</td>\n",
       "      <td>suicide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text        class\n",
       "0           0  Ex Wife Threatening SuicideRecently left wife ...      suicide\n",
       "1           1  weird not get affected compliments coming some...  non-suicide\n",
       "2           2  Finally almost never hear bad year ever swear ...  non-suicide\n",
       "3           3                  need helpjust help me crying hard      suicide\n",
       "4           4  lostHello name Adam and struggling years and a...      suicide\n",
       "5           5  Honetly idkI not know even feel like nothing a...      suicide\n",
       "6           6  Trigger warning Excuse self inflicted burns kn...      suicide\n",
       "7           7                   ends tonight cannot anymore quit      suicide\n",
       "8           8  Everyone wants edgy and making me self conscio...  non-suicide\n",
       "9           9  life years oldHello year old balding male hair...      suicide"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3=[]\n",
    "for i in l1:\n",
    "    if i[0][\"label\"]==\"NEGATIVE\":\n",
    "        l3.append(\"suicide\")\n",
    "    else:\n",
    "        l3.append(\"non-suicide\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.62\n"
     ]
    }
   ],
   "source": [
    "l2=df_class[0:100]\n",
    "print(accuracy_score(l2,l3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
